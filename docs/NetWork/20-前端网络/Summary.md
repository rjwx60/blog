# 总结

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200920205934.png" alt="截屏2020-09-20 下午8.59.09" style="zoom:67%;" />



## 一、基本

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200908000056.png" style="zoom:50%;" />

**<u>CDN</u>**：CDN 是构建在现有网络基础之上的智能虚拟网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率；CDN 作用是减少传播时延，寻找到最近的节点，是典型的"以空间换时间"技术；访问过程如下：

- 首先，用户点击网站页面上的内容 URL，经过本地 DNS 系统解析，DNS 系统会最终将域名的解析权交给 CNAME 指向的 CDN 专用 DNS 服务器；
- 然后，CDN 的 DNS 服务器将 CDN 的全局负载均衡设备 IP 地址返回用户；
- 然后，用户向 CDN 的全局负载均衡设备发起内容 URL 访问请求；
- 然后，CDN 全局负载均衡设备根据用户 IP 地址，及用户请求的内容 URL，选择一台用户所属区域的区域负载均衡设备，告诉用户向这台设备发起请求；
- 然后，区域负载均衡设备会为用户选择一台合适的缓存服务器提供服务，选择的依据基于下述条件综合分析后，区域负载均衡设备会向全局负载均衡设备返回一台缓存服务器的 IP 地址；
  - 根据用户IP地址，判断哪一台服务器距用户最近；
  - 根据用户所请求的URL中携带的内容名称，判断哪一台服务器上有用户所需内容；
  - 查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力；
- 然后，全局负载均衡设备把服务器的 IP 地址返回给用户；
- 最后，用户向缓存服务器发起请求，缓存服务器响应用户请求，将用户所需内容传送到用户终端；若这台缓存服务器上并无用户想要的内容，而区域均衡设备依然将它分配给了用户，则此台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地；
- 如果，当 CDN 缓存服务器中无符合用户要求的资源时，服务器会请求上级缓存服务器，以此类推，若最后还是没有，就会回到主服务器获取资源；
  - 用户访问时，如节点上无缓存，则会回源拉取资源；
  - CDN节点上的文件过期，会回源拉取资源；
  - 若为不缓存文件，用户访问时，会直接回源拉取资源；



## 二、IP

IP 负责电脑门户寻找；TCP 主要负责找到门户后的端口寻找；待整理+总结



## 三、TCP

### 3-1、基本与首部字段

**<u>TCP基本</u>**

<u>TCP 协议特点</u>

- 可靠性：无论网络出现何种状况，均能保证信息可达
  - 有状态：记录已发数据、对方已收数据、未收数据，并保证数据包按序到达，不丢包；
  - 可控制：自适应调整自身行为，配合网络环境控制发送行为；
- 面向连接：一对一，客户端与服务器的连接，双方通信前需三次握手
- 基于字节流
  - 消息无边界：无论消息多长均能传输，但有 MSS 字段控制防止 IP 层自行分段降低传输效率
  - 有序；即便先到达，也不能交予应用层处理

<u>UDP (与 TCP 相对)</u>

- 面向无连接：无需建立连接过程
  - 发送时，应用层将数据传递给传输层 UDP，而 UDP 只会给数据增加 UDP 头标识其为 UDP 协议，然后就传递给网络层；
  - 接收时，网络层将数据传递给传输层，UDP 只去除 IP 报文头就传递给应用层，不会任何拼接操作；
- 不可靠性：无连接，无法保证可靠性，且无拥塞控制，丢包无法处理
- 高效：头部很小，只有8字节，TCP 则有20多字节

<u>TCP 协议任务</u>

- 进程寻址/处理并将字节流打包为报文段/创建管理连接/可靠传输/流量与拥塞控制



**<u>TCP首部字段</u>**

- 源端口、目的端口
  - 用于定义 TCP 连接，通过 TCP 四元组唯一标识一个连接：源地址、源端口、目的地址、目的端口

- 序列号Seq、确认号Ack
  - 用以唯一标识 TCP 报文，类似物流系统的订单号，ACK 除了标识，还用于确认报文，以实现数据可达性
  - 初始序列号-ISN—报文段第一个字节的序列号；
  - 因 TCP 报文段在经过网络路由后会存在延迟抵达或排序混乱情况，故需要 ISN，通过半随机构造法构建
  - 注意：ISN 的构建使用半随机方法构建(基于时钟+偏移量+加密散列函数+每隔 4 ms 加1)，以确保不同连接间唯一性，防止重叠，避免不同连接间的相互影响，也为了避免连接被攻击者预测、伪造报文；
  - 注意：三次握手核心目的之一就是交换双方 ISN，交换后才可得知对方发送信息的初始位置

- 窗口大小 Window：存放窗口缩放的比例因子，用于流量控制
- 校验和 Checksum：校验数据完整不破坏性
- 标记位 TCP Flag
  - ACK：该字段为一表示确认号字段有效；此外，TCP 还规定在连接建立后传送的所有报文段都必须把 ACK 置为1；
  - SYN：当 SYN=1，ACK=0 时，表示当前报文段是一个连接请求报文。当SYN=1，ACK=1时，表示当前报文段是一个同意建立连接的应答报文；
  - RST：即 Reset，重置报文标志，用来强制断开连接；
  - RST：该字段为一表示当前 TCP 连接出现严重问题，可能需要重新建立 TCP 连接，也可以用于拒绝非法的报文段和拒绝连接请求；
  - FIN： 即 Finish，结束报文标志，表示发送方准备断开连接；
  - PSH： 即 Push，告知对方此数据包收到后应马上交给应用层，而非等到缓冲区满后再提交(接收端收到报文时，接收方应尽快将缓冲区内容上交应用层处理)；
  - URG：终止行为，优先处理含此标志位的报文；比如 ctrl + C 取消 npm 包下载；

- 可选项 TCP Options
  - 时间戳 TSOPT 及其作用：
  - 作用A：计算往返时延-RTT，计算流程如下：
    - 请求时 timestamp 存放发送时间tA-1
    - 响应时 timestamp 存放响应时间 tB-1 timestamp echo 存放tA-1
    - 接收后，记录收到时间 tA-2，并拿出 tA-1 进行相减即可
  - 作用B：防止序列号回绕：Sep 到达最大值时会从 0 重新循环，防止网络存在两份序列号相同报文





### 3-2、连接管理

**<u>3-2-1、TCP连接管理：建连之三次握手</u>**

<u>**握手目的**</u>：交换彼此 ISN、交换后才可得知对方发送信息的初始位置、交换 TCP 通讯参数(窗口大小、校验和算法等)

<u>**握手过程&状态变化**</u>

- CLOSED-SYN_SENT-ESTABLISHED

- CLOSED-LISTEN-SYN_RECEIVED-ESTABLISHED

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112341.png" style="zoom:50%;" />

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924092023.png" alt="截屏2020-09-24 上午9.19.53" style="zoom: 67%;" />

<u>**握手性能优化**</u>

- 1、调整超时时间与缓存队列长度：当客户端发送SYN到服务端，服务端收到后回复 ACK和SYN，状态由LISTEN变为SYN_RCVD，此时连接套接字就被推入半连接队列(SYN Queue)；当客户端返回ACK，服务端接收后，三次握手完成；此时连接套接字将被推入另一个 TCP 维护队列，也即全连接队列(Accept Queue)，并等待被具体应用调用 accept 方法取走
- 2、TFO：首次连接服务端多回送 Cookie 供客户端缓存，若后续再次建立连接时，客户端一并传送 Cookie，服务端识别后将 Data 随 SYN/ACK 报文回传
  - 优势：TFO 充分利用一个RTT，省去客户端 ACK 确保报文，降低二次连接时的时延，提前进行数据传输
  - 注意：服务端为客户端建立 Cookie 的前提是双方均支持 TFO，随后当客户端再次向服务器建立连接时，则复用缓存 cookie，服务端验证通过后才能在首次握手中传递消息
- 3、TCP_DEFER_ACCEPT：当服务器收到 ACK 分组后，并将 SYN 放入相应 ACCEPT 队列中，但内核不立即激活相应应用程序，而是等待后续数据到达再激活，以提升效率；

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112354.png" style="zoom:50%;" />

<u>**握手安全问题**</u>

- SYN Flood：即在短时间内，伪造大量不存在的IP地址的 SYN 报文
- 危害1：服务回送 ACK 但无法收到对方 ACK，使 backlog (SYN) 队列被大量处于 SYN_RCVD 状态连接占满，无法处理正常请求；
- 危害2：服务端长时间收不到客户端ACK，导致服务端不断重发数据，耗费服务器资源；
- 防御1：调整 SYN 队列连接数
- 防御2：减少 SYN + ACK 重试次数，避免大量的超时重发；
- 防御3：tcp_syncookies

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924092532.png" style="zoom: 50%;" />

<u>**握手其他问题**</u>

<u>两次握手为何不可</u>：SYN-SYN/ACK-Data

- 即服务端不必等待客户端的 ACK报文，就可以接受数据，也就是说客户端发起一个 SYN 就可以建立连接
- 在这种场景下，如果发起2个连接，其中1个滞留，另一个建立并通讯并关闭，随后滞留才到达…
- 即服务端接收客户端 SYN 后回送 SYN/ACK 不进行客户端的再次确认环节 ACK
- 前两次握手必须，而第三次是为了：防止已失效请求报文段突然又传送到服务端而产生连接的误判
- 即客户端发起连接请求后，一旦服务器收到就完成连接建立，并腾出系统空间，发送数据，但若请求出错(滞留网络中的失效报文)，则会令服务端无端建立无用连接

<u>四次握手如何</u>：可以但没必要，降低通讯效率

<u>同时发起握手</u>：即同时发送SYN给对方，并同时进入SYN_SENT状态，收到对方SYN后进入SYN_RECEIVED

- 相比于常见连接，客户端多出 SYN-RECEIVED 状态，服务端多出 SYN-SENT 状态

<u>握手携带数据</u>：三次握手时，客户端已处于 ESTABLISHED 状态，且已确认服务器收发能力，故可携带

- 若为普通握手连接，则第三次可携带，前两次不可携带，以减少服务器被攻击风险，提升连接效率
- 若为开启了 TFO 的握手连接，则二次建立连接时，首次握手可携带一次建立连接服务器下发的 cookie 认证信息，二次握手(服务端响应)则可携带响应相关数据

<u>连接建立超时</u>：

- 若连接不存在主机，则会先发生连接建立超时现象，后续客户端会收到“无法到达主机”消息，并发生指数回退行为
- 若首次发送 SYN 失败，第二次尝试连接时间隔会变长，比如首次发送后，二次发送在 3 秒后，三次发送在6秒后，四次在 12 秒…此行为亦称 指数回退 



**<u>3-2-2、TCP连接管理：断连之四次挥手</u>**

**<u>挥手过程&状态变化</u>**

- ESTABLISHED-FINWAIT1-FINWAIT2-TIMEWAIT-2MSL
- ESTABLISHED-CLOESDWAIT-LASTACK

- 2MSL意义：保证 TCP 协议全双工连接可靠关闭
  - 若客户端回送 ACK 后直接 CLOSED，此时，若出现网络原因导致 ACK 报文丢失，服务端则会在超时后重发 FIN，此时若客户端在原有端口上已建立别的连接，就会造成信息混乱；
  - 保证至少一次报文往返时间内端口不可复用；
  - 若客户端回送 ACK 后直接 CLOSED，此时，若客户端重新向服务端发起连接，且若使用相同端口(新旧连接)建立连接，此时，若旧连接的数据仍滞留网络中，并在建立新连接后到达，则会误将旧数据包当作新连接，导致数据混淆；(若TIME_WAIT过短或没有，若后续复用端口，则会导致接收方数据错乱
  - TIME_WAIT 有保护作用，避免延迟到达数据扰乱新连接
  - 1 个 MSL 确保四次挥手中主动关闭方最后的 ACK 报文最终能达到对端；
  - 1 个 MSL 确保对端没有收到 ACK 重传的 FIN 报文可以到达；

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112341.png" style="zoom:50%;" />

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924093001.png" alt="截屏2020-09-24 上午9.29.56" style="zoom:67%;" />

**<u>挥手性能优化</u>**：主动发起关闭方会经历 2MSL，期间端口被占用，若发起方为服务端则还需同时处理大量TCP连接，优化关闭流程

- tcp_tw_reuse
- tcp_tw_recycle & tcp_max_tw_buckets

**<u>TCP 其他问题</u>**

<u>四次原因</u>：因服务端在接收到 FIN 后，往往不会立即返回 FIN，而须等到服务端将所有报文均发送完毕/处理请求完成后，才能发 FIN；此时先发送 ACK 表示已收到客户端的 FIN，等服务端处理完毕后才发 FIN，再加上客户端的 ACK 确认，导致四次挥手；若为三次挥手：等同于服务端将 ACK 和 FIN 发送合二为一，某些情况可以实现，但更多的是其中的长时间延迟可能会导致客户端误以为 FIN 没有到达服务端而不断重发 FIN；

<u>重置报文</u>：当发现到达报文段对相关连接而言是不正确时，TCP 会发出重置报文段，此会导致 TCP 连接的快速拆卸：某连接请求到达本地却无相关进程在目的端口监听；具体表现为 UDP 协议会生成一 ICMP 目的不可达信息，而 TCP 则使用重置报文段来代替完成；

<u>替代 FIN 来终止连接</u>：正常终止连接的方法是发送 FIN，此亦称为有序释放，而在任意时刻通过重置报文段来释放连接的则称终止释放，此时任何排队的数据都将会被抛弃；

<u>半开连接</u>：若 A 端在未告知 B 端情况下 A 关闭或终止连接，则称此 TCP 连接处于半开状态；半开通常发生在主机崩溃或非正常关机的情况下；TCP 规定接收方回复一个重置报文段作为响应；

<u>时间等待错误</u>：在 TIME_WAIT 期间收到连接的报文或更为特殊的 RST 重置报文段时，就会发生时间等待错误 TIME-WAIT Assassination-TWA，即 RST 能破坏 TIME_WAIT 状态并强制连接提前关闭；目前许多系统通过不对 TIME-WAIT 状态时收到的 RST 报文作出回应来规避上述问题；

<u>同时发起挥手</u>：略；





### 3-3、超时重传与流量控制

**<u>TCP超时重传</u>**

<u>ARQ</u>

<u>超时重传时间的计算</u>—RTO计算：RTO 的设置是保证 TCP 性能的关键

- 经典方法
- Jacobson/Karels 算法

<u>重传机制的演变</u>

- PAR 基于计时器的重传：即发送报文后，开启定时器，若限定时间内收到对方 ACK 代表接收成功，否则进行重传
  - 网络利用率和效率低下，且对方接收与处理能力有限，需增加 limit 字段限制发送方
- PAR 增强：即并发发送；
- 快速重传：接收方每收到一个 失序报文 即立刻发出过往接收到的报文的重复确认，而不用等到接收方自己发送数据时才进行捎带确认，以让发送方及早获悉有报文段没有到达
  - 问题：无法得知具体缺失报文，是仅重传 M3(保守乐观)，还是重传所有未确认报文(积极悲观)；
  - 前者在大量丢包时效率低下，后者可能浪费带宽；

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924093334.png" alt="截屏2020-09-24 上午9.33.18" style="zoom:50%;" />

- 选择性重传：解决上述问题；
  - 选择性重传(SACK，Selective Acknowledgment)，在 TCP 头部选项，通过 SACK 的 left edge、right edge 告知发送端已收到的区间的数据报，以更有效地重传；
  - 区别：快速重传，解决是否需要重传的问题；选择性重传(SACK，Selective Acknowledgment)，解决如何重传的问题；

**<u>TCP 流量控制：</u>**

- TCP滑动窗口概念
- Nagle算法与延迟确认
- 流量控制流程
  - 首先，此时若 A 给 B 发送 100 字节，则 A 的SND.NXT 右移 100 字节，即 A 当前的可用窗口减少 100 字节；
  - 然后，100 字节到达 B 端，并被放入 B 的缓冲队列中，但假若 B 目前无法处理那么多字节，只能处理 40 个字节，那么其余 60 个字节被留在缓冲队列中；因处理能力低下，故 B 的接收窗口应缩小，比如这里应缩小 60 字节，由 200 变为 140 字节，因缓冲队列还有 60 个字节没被处理；所以，B 在接下来的 ACK 报文中携带上缩小后的滑动窗口大小，即140；
  - 然后，A 端收到后，确认 B 已处理 40 字节，SND.UNA 右移 40 字节，并调整发送窗口大小为 140 字节；
  - 最后，如此往复；
  - 注意：着重个人理解；



### 3-4、拥塞控制

**<u>拥塞控制的发展历程</u>**

- 以延迟作检测依据
- 以丢包作为检测依据
  - TCP 拥塞控制操作是基于数据包守恒原理运行：TCP 发送方的拥塞控制操作是由 ACK 的接收来驱动或控制：当 TCP 传输处于稳定阶段，接收到 ACK 回复表明发送的数据包已被成功接收否则不能，继而推理知，稳定状态下的 TCP 拥塞行为，实际是试图使在网络传输路径上的数据包守恒；而 TCP 拥塞控制的两个核心算法：慢启动和拥塞避免，是基于包守恒和 ACK 时钟原理，注意此两算法不可同时运行，但可相互切换；
- 以探测带宽作为检测依据
  - 2016年 Google 提出基于带宽探测的拥塞控制—BBR，极大提升了 TCP 的拥塞控制性能；



**<u>以丢包作为检测依据的拥塞控制：</u>**

<u>慢启动</u>：当新的 TCP 连接建立、检测到由重传超时 RTO 导致的丢包、发送端长时处于空闲状态时，需要执行慢启动；目的是让 TCP 在用拥塞避免探寻可用带宽前得到 cwnd 值，帮助 TCP 建立 ACK 时钟；注意：慢启动并非指 cwnd 增长速率慢，而是指初始值小；

- 首先：TCP 刚开始传输数据时，并不清楚此时的网络状态，可先保守地缓慢地由小到大增大发送窗口，即逐渐增大拥塞窗口值；即 TCP 以发送一定数目的数据段开始慢启动，此时的窗口称为 初始窗口 IW (Initial *Window*)(拥塞窗口-cwnd) 
- 然后：在接收到一个数据段的 ACK 后，cwnd 值由 1(SMSS) 变 2，随即发送两个数据段；若成功接收到相应新的 ACK，cwnd 便会由 2 变 4，以此类推，若一直未发生丢包且每个数据包都有相应 ACK，则 k 轮后 W 值为 W = 2^k，k = log2W，增长极快
- 然后：cwnd 会快速增长，并同时确立一个慢启动阀值，一旦到达阀值，则进入拥塞避免阶段(避免后续因增长速度极大占用大量网络资源、增加网络不稳定性)，此时 cwnd 增长模式由指数级切换为线性级；

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112429.png" style="zoom:50%;" align=""/>

<u>拥塞避免</u>：为防止 cwnd 增长过大引起网络拥塞，慢启动阶段还需计算并设置 慢启动阀值/门限 (ssthresh-slow start threshold) 状态量，当到达此值时则启用拥塞避免算法，以线性方式增加 cwnd，让 cwnd 缓慢增大，而非无节制增长；

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112430.png" style="zoom:50%;" />

<u>发生丢包</u>：无论在慢启动阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞(RTO)，则将设置慢启动阀值/门限(ssthresh)为出现拥塞时的，发送窗口值的一半(但不能小于2)，然后将拥塞窗口 cwnd 重新设置为 IW，再次进入慢启动，以迅速减少主机发送的分组数，使发生拥塞的节点有充足时间将队列中积压的分组处理完毕；

- 注意：同一时刻只运行单个算法，但算法间可相互切换：
- 当 cwnd < ssthresh 时，使用慢启动算法；
- 当 cwnd = ssthresh 时，可使用慢启动算法，亦可使用拥塞避免算法；
- 当 cwnd > ssthresh 时，使用拥塞避免算法；

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112432.png" style="zoom:50%;"/>

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112433.png" style="zoom:50%;"/>

<u>快速重传与快速恢复</u>：在过去没有快速重传时，须等待 RTO，再发送 pkt1，效率低下，快速重传要求接收方每收到一个 失序报文 即立刻发出重复确认，而不用等到接收方自己发送数据时才进行捎带确认，以让发送方及早获悉有报文段没有到达；但是快速重传意味着丢包，但收到重复 ACK，意味着网络仍在流动，没必要马上进入慢启动，因其会突然减少数据流，在正常且未失序 ACK 段到达前，启动快速恢复，更好利用网络资源；

<u>快恢复算法与快速重传配合使用：</u>

- 首先，当发送方连续收到3个重复确认时，就执行“乘法减小”算法，将 慢启动阀值/门限 (ssthresh) 减半，但注意并非执行慢启动算法，而是将 cwnd 值设置为 慢启动阀值/门限 (ssthresh) 减半后的数值；
- 然后，开始执行拥塞避免算法 (“加法增大”)，使拥塞窗口缓慢地线性增大；
- 总结：
  - 慢启动阀值/门限 (ssthresh)降低为 拥塞窗口(cwnd) 的一半
  - 拥塞窗口(cwnd) 大小变为 慢启动阀值/门限 (ssthresh)
  - 拥塞窗口(cwnd) 线性增加
- 注意：快速恢复时 cwnd 为 ssthresh + 3 * MSS 是当时调研网络环境得出的经验数据；
- 注意：不管单丢包还是连续丢包，每次仍返回应收但未收的 Seq ACK；
- 注意：接收端中，当接收到的包的 Sequence number 与接收窗口中的 rcv.nxt 一样，才讲 ACK 的 Acknowledge number 更新为 rcv.nxt 值；否则 ack number 一直不变，此时发送端在连续收到含有不变 ack number 的 ACK，就可断定某包未被对方收到，从而启动快速重传；

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112437.png" style="zoom:50%;"/>

<u>**以探测带宽作为检测依据**</u>

2016年 Google 提出基于带宽探测的拥塞控制—BBR，极大提升了 TCP 的拥塞控制性能；

背景1：网络中的瓶颈路由器：当其等待队列全满或过载时就会发送拥塞，下图为大管道向小管道传输数据引发拥堵；

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112440.png" style="zoom:50%;"/>

背景2：传统拥塞算法问题：变化不平滑；而 CUBIC 拥塞控制算法变化平滑，但也基于丢包驱动，带来的时延也很大；

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112442.png" style="zoom:50%;"/>

BBR 通过寻找最佳控制点来实现：

- 若反复、多次测量 RTT，并取噪声最小值，则近似得出 RTprop；
- 若反复、多次测量发送速率，取最大值，则近似得出 BtlBw；由此2个值找到最佳控制点；
- 并通过引入 pacing_gain，其用于检测带宽变化和线路变换，进行周期性改变发送速率，来观察带宽与 RTT 的关系，以迅速寻找最佳控制点；



<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112443.png" style="zoom:50%;"/>

- 上图：y 轴 RTT，一开始，RTT不变，带宽增加，表示应用端进程并未开足马力发送数据，故 RRT 不变，带宽增加；等达到最大带宽后，路由器开始挤压队列，此后 RTT 开始变大；
- 下图：y 轴 带宽，一开始带宽利用增加，到后面因达到最大带宽而不变，此时出现挤压；
- 结论：传统拥塞控制在丢包时进行控制，但更好控制位置应在 RTT 开始变化时，此时控制发送速率，可享受最大带宽，且拥有最小时延和最低丢包率；
- 测量：控制点位置：将路由器的缓冲队列降至 0，而关注路由器发现，刚开始挤压时即最佳控制点，即空队列时；
- 注意：上述图表中，RTT 与 BW 独立变化，即 RTT 变慢时，BW 吞吐量可维持不变；同理，RTT 不变时，BW 可升高或降低；

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112444.png" style="zoom:50%;"/>

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112445.png" style="zoom:50%;"/>













### 3-5、TCP 其他内容

**<u>TCP Keep-alive 保活探测</u>**

对长时间未发送数据的连接进行关闭处理(双向，两方均可检测，探测对端连接是否仍然有效)，以减少内存和端口等资源占用，关闭流程：若达到关闭条件，则向对方发送探测包：

- 若收到对方应答则表示此连接仍活跃，此时进入下一潜伏状态；
- 若无收到对方应答，则间隔一定时间后再发送，若上述探测达到一定次数则关闭连接；

<u>TCP KeepAlive & HTTP KeepAlive 区别：</u>

- TCP 的 Keepalive 机制意图在于探测连接的对端是否存活；

- HTTP 协议的 Keep-Alive 意图在于 单个 TCP 连接复用，同一个连接上串行方式传递请求-响应数据；

**<u>TCP多路复用</u>**：多路复用：在一个信道上传输多路信号或数据流的过程和技术；比如频分时分码分复用

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112501.png" style="zoom:50%;" align=""/>

TCP 是面向字节流的不定长的协议，较难实现 TCP 多路复用，但可从编程层面实现 TCP 多路复用；

- 1、非阻塞 socket：同时处理多个 TCP 连接
- 2、epoll + 非阻塞 socket
- 3、epoll + 非阻塞 socket + 同步编程 = 协程

HTTP2 的多路复用是基于 TCP 连接上的多路复用

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200919112502.png" style="zoom:50%;" align=""/>









## 四、DNS

主要看 DNS 域名解析流程；

**<u>DNS 基本：</u>**

发展的角度解释

使用 UDP 减少响应时间 53

- 涉及 TCP 与 UDP 区别：DNS交易时间，减小响应时间，有效信息占比高；
- TCP连接时间 + DNS交易时间(若查询冷门域名信息，则还可能会经过域名根服务器、一二级域名服务器迭代查询，成本高昂)；

**<u>DNS 域名服务结构</u>**

- 根子结构
  - 根 DNS
  - 顶级域 DNS
  - 权威 DNS
- 分布式：单点集中问题(维护、容量、距离、宕机)

### 4-1、域名解析流程

**<u>DNS 域名解析流程</u>**

- 首先，浏览器自身 DNS 缓存
- 然后，主机解析器缓存
  - 若在本地配置 Hosts 文件，则在启动 DNS 客户端服务时，该文件中所有的主机到地址的映射均会预加载到缓存中；
  - 从以前的 DNS 查询的答复中获得的资源记录将添加到缓存中并保留一段时间；
- 然后，本地配置的首选 DNS 服务器发起递归查询—DNS 服务器配置域中包含的资源记录—DNS 服务器已缓存的映射关系
- 然后，DNS 服务器代为用户，发起迭代查询，向附近的 DNS 服务器逐个询问；
- 然后，若查询仍失败，则根据本地 DNS 服务器的设置(是否设置转发器)进行查询
  - 设置转发器：向上级 DNS 服务器—上上级服务器—上上上..来发起递归查询
  - 未设置转发：向根、顶级域、权威域等层次来进行迭代查询
- 最后，若还是查询失败
  - 查询 NetBIOS name *Cache*
  - 查询 WINS 服务器(NETBIOS 名称和 IP 地址对应的服务器)
  - 客户端进行广播查找 
  - 客户端读取LMHOSTS 文件

- 总结：主机向本地域名服务器的查询一般都是采用递归查询；本地域名服务器向根域名服务器的查询的迭代查询

**<u>DNS 迭代与递归查询区别</u>**

<u>即 DNS 解析算法</u>，个人理解前者结构是一个重复调用自身(但参数不同)的结构(很形象，即迭代)，后者结构是一个嵌套回调；

前者按服务器逐个查询；后者通过服务器链式查询；综上，递归查询时客户单只发送查询到第一个服务器，然后服务器将请求发送到下一个服务器，直到查询被解析；而在迭代查询中，客户端负责将查询发送到不同的服务器，直到查询被解析；

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200907234839.png" style="zoom:50%;" />

**<u>DNS 分析工具与报文结构</u>**

- dig www.baidu.com

- DNS 报文结构：
  - 请求报文(Question 字段、QNAME 编码规则、QTYPE 常用类型、QCLASS) 
  - 响应报文(Answer 字段、TTL、RDATA、NAME)

**<u>DNS 安全与优化</u>**

DNS 分布式拒绝服务 (DDoS) 带宽洪泛攻击，即攻击者向每个 DNS 根服务器/顶级域名服务器发送大量分组，使得大多数合法  DNS 请求无法得到应答；

对策A：使用分组过滤器保护，阻挡所偶有指向根服务器的 ICMP ping 报文；

- ICMP是 Internet 控制报文协议；是 TCP/IP 协议族的一个子协议，用于在 IP 主机、路由器之间传递控制消息；

- ping 是 DOS 命令，通常用于检测网络连接和故障

- Ping 是 Internet 包资源管理器，用于测试网络连接量的程序；Ping向目的地发送 ICMP 回声清除消息，并报告是否接收到所需的ICMP 回声响应；

对策B：启动本地服务器的缓存技术，本地服务器缓存顶级域名服务器地址(便可绕过迭代查询根级服务器)；

**<u>DNS 优化方式</u>**

当客户端 DNS 缓存为空，DNS 查找数量与要加载的  Web 页面中唯一主机名的数量相同(含各类资源主机名)

- 所以：减少主机名数量可减少 DNS 查找数量，提升页面加载速度；
- 注意：减少主机名与尽可能让浏览器并行下载相冲突，需合理处理关系；
- 建议：将组件放到至少2个但不多于4个的主机名下，减少 DNS 查找的同时也允许高度并行下载；



## 五、HTTP

HTTP 协议是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范；其通常跑在TCP/IP协议栈之上，依靠IP协议实现寻址和路由、TCP协议实现可靠数据传输、DNS协议实现域名查找、SSL/TLS协议实现安全通信；当然，*WebSocket*、DNS 依赖于 HTTP；HTTP 责任是定义数据形式让对方理解；

- TCP 负责数据在计算机间可靠、稳定、高效传输；
- HTTP 责任是定义数据形式让对方理解；
- TCP 负责数据在计算机间可靠、稳定、高效传输；



### 5-1、基本信息

**<u>HTTP 各版本总览</u>**

- HTTP/0.9：GET/index.html；
  - 仅为学术交流，基于请求和响应的模式，在网络中传输HTML超文本的内容
  - 只有一个请求行，没有HTTP请求头和请求体；同样，服务器也没有响应头信息，只是返回了数据
- HTTP/1.0：引入请求头、响应头，同时也引入状态码，为减轻服务器压力，还提供  Cache机制；而服务器需要统计客户端的基础信息，加入用户代理字段、不再局限于 ASCII 编码、短连接
- HTTP/1.1
  - 通过在请求头中增加 Host字段，增加对虚拟主机的支持
  - 引入 Chunk transfer 机制 来增加对动态生产内容的支持
  - 引入 客户端Cookie机制 和 安全机制；
  - 引入 KeepAlive 实现长连接，即复用同一 TCP 连接，传输多个 HTTP 请求；
  - 缺点：对宽带利用率低：TCP 的慢启动、HTTP/1.1 队头阻塞的问题、同时开启多条 TCP 连接，会竞争固定带宽；
- HTTP/2
  - 多路复用：HTTP/2 使用多路复用机制解决了上述问题；一个域名只使用一个 TCP 长连接和消除队头阻塞问题；通过引入二进制分帧层，实现了 HTTP 的多路复用技术；
  - 服务器推送：服务器可提前将数据推送到浏览器，浏览器有权选择是否接受；浏览器发送 RST_STREAM帧 可以选择拒收；
  - 头部压缩：头部压缩大大提升传输效率；HTTP/2 使用 HPACK 算法，在客户端和服务器建立字典，用索引号表示重复的字符串，还采用哈夫曼编码来压缩整数和字符串
  - 缺陷：
    - TCP 队头阻塞：HTTP/2 只解决应用层面的队头阻塞，而阻塞问题根源在 TCP 协议本身；TCP 会因为单个数据包的丢失而造成的阻塞称为 TCP 队头阻塞； 
    - TCP 建立连接延时：TCP 及 TCP+TLS 建立连接的所产生的延时也是影响传输效率的一个主要因素；
    - TCP 协议僵化：中间件僵化：将在互联网的各处搭建的设备叫做中间设备(中间件)，比如路由器、NAT、防火墙、交换机等，它们通常依赖一些很少升级的软件，这些软件使用了大量的 TCP 特性，设置后便很少进行更新；而这就对我们更新 TCP 时造成巨大困难， 新协议的数据包经过这些中间件时，它们不会去理解包的内容从而丢弃掉这些数据包；操作系统僵化：因为 TCP 协议都是通过操作系统内核来实现的，应用程序只能使用不能修改；而通常操作系统的更新都滞后于软件的更新，所以想要更新操作系统内核中的 TCP 协议也是非常困难；
- HTTP/3：其选择了个折衷的方法：基于 UDP 实现了类似于 TCP 的多路数据流、传输可靠性等功能，即 QUIC 协议；
  - 实现了快速握手功能、集成 TLS 加密功能、实现 HTTP/2 中的多路复用功能；
  - 实现了类似 TCP 的流量控制、传输可靠性的功能；

**<u>HTTP 特点</u>**

- 无状态(优缺同体)：状态指通信过程的上下文信息；无状态指每次请求均为独立无关联，默认不保留状态信息；具体场景具体分析；比如若仅为获取某些数据的场景下，而无需保存连接的上下文信息，此时的无状态能有效减少网络开销；
- 灵活可扩展：语义自由：只规定基本格式(分隔符、换行分隔等)，而其他部分无严格语法限制；形式多样：传输形式多样，可传输文本、图片、视频等任意数据；

- 请求响应模式：报文须一发一收、有来有回；
- 持久连接：建立一次 TCP 连接即可进行多次请求或响应的交互，只要有一方没有明确的提出断开连接，则保持连接状态；原理：HTTP的初始版本是每进行一次HTTP通信就要断开一次TCP连接，下次再进行的时候又要重新连接断开。再如今请求的资源越来越大，每次请求如果都有无谓TCP连接和断开是很大的开销；优点：减少 TCP 连接和断开的造成的额外开销，减轻服务端的负载，Web 页面加载变快；注意：HTTP/1.1 中所有连接均默认持久连接 (也即首部字段 Connection: keep-alive，若想要关闭可将值设置为 close)，但 HTTP/1.0 并未标准化

**<u>HTTP 不足</u>**

- 无状态：状态指通信过程的上下文信息；无状态指每次请求均为独立无关联，默认不保留状态信息；具体场景具体分析；对于一些长连接的场景需要保存上下文信息，以免传输重复的数据；对于一些应用只是为了获取数据不需要保存上下文信息，无状态减少了网络开销；WebSocket 补丁解决；
- 明文传输：即报文传输使用文本形式而非二进制形式，虽便于调试但暴露了内部信息，内容能被窃取；通过 HTTPS 解决
- 队头阻塞：当 http 开启长连接时将共用一个 TCP 连接，同一时刻只能处理一个请求，此时若某请求耗时过长，则会导致其它请求处于阻塞状态；根本原因：在于 HTTP 基于 请求响应 模型，在同一 TCP 长连接中，前一请求没有得到响应，后面的请求就会被阻塞；注意：与 TCP 队头阻塞区别：TCP 传输的单位是数据包，其队头阻塞表示的是前一个报文没有收到便不会将下一个报文上传给应用层；而 HTTP 队头阻塞是在 请求-响应 层面，前一个请求还没有处理完，后面的请求就被阻塞；
  - 并发连接：一个域名允许分配多个长连接，相当于增加任务队列数量；RFC2616 规定过客户端最多并发 2 个连接，而实际中的浏览器上限要比它大，比如 Chrome 中是 6；
  - 域名分片：通过增加域名以实现增加发送数量；比如：content1.TLP.com 、content2.TLP.com
  - HTTP/2：上述 HTTP/1.1 方式并无真正从协议层面解决问题，只是增加 TCP 连接分摊风险，且多条 TCP 连接也会竞争有限的带宽，让真正优先级高的请求不能优先处理；而 HTTP/2 的多路复用真正从协议层面解决此问题

**<u>HTTP 格式</u>**

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200907235830.png" style="zoom:35%;" align="" />

- 起始行
  - 请求报文起始行由：方法 + 路径 + http版本 组成，比如：GET /home HTTP/1.1
  - 响应报文起始行由：http版本 + 状态码 + 原因 组成，比如：HTTP/1.1 200 OK
  - 注意：响应报文的起始行也叫做状态行；
  - 注意：起始行中每2个部分间用空格隔开，最后一部分后还应接换行，遵循 ABNF规范 (https://en.wikipedia.org/wiki/Augmented_Backus%E2%80%93Naur_form)
- 头部
  - 字段名不区分大小写、不允许出现空格，不可出现下划线
  - 字段名后面必须紧跟冒号 : 不得空隙；
- 空行：用以区分头部与实体，若将空行位置上移，则往后内容均被视为实体部分；
- 主体：即数据部分



### 5-2、首部字段

**<u>HTTP 请求方法</u>**

- GET：获取资源，幂等操作
- HEAD：获取报文首部，和GET很像但是不返回报文主体，幂等操作
- POST: 创建或更新资源，非幂等操作
- PUT: 创建或更新资源本身，幂等操作
- PATCH：对资源进行局部更新，幂等操作
- DELETE：删除资源，和PUT功能相反，幂等操作
- OPTIONS：查询服务器端支持的HTTP方法种类(幂等操作)
- CONNECT：建立连接隧道，用于代理服务器，幂等操作
- TRACE：追踪请求，查询发出去的请求是怎样被加工/篡改的，幂等操作。容易引发XST跨站追踪攻击；
  - 注意：OPTIONS、CONNECT、TRACE只在HTTP/1.1以上被支持
  - 注意：LINK、UNLINK在HTTP/1.1中被废弃
- <u>GET & POST区别：</u>

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924100929.png" alt="image-20200924100929111" style="zoom:50%;" />

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924100948.png" alt="image-20200924100948573" style="zoom:50%;" />



**<u>HTTP Status Code：</u>**

1XX：表示请求已接收到，需要进一步处理才能完成，HTTP/1.0 不支持

- 100 Continue：继续，客户端应继续其请求，上传大文件前使用；
- <u>101 Switching Protocols：切换协议；服务器根据客户端的请求切换协议，但注意只能切换到更高级的协议；</u>
  - 比如：切换到 HTTP 的新版本协议；
  - 比如：当 HTTP 升级为 WebSocket 时，若服务器同意变更，也会回送此码；

- 2XX：表示成功状态；
  - 200 OK：成功状态码；响应体有数据；一般用于GET与POST请求；
  - 201 Created：已创建；成功请求服务端并有新资源在服务器端被成功创建；
  - 202 Accepted：已接受；服务端已接受请求但未处理完成；
  - 203 Non-Authoritative Information：非授权信息；请求成功，但返回的 meta 信息不在原始服务器，而是一个副本；
  - <u>204 No Content：含义与 200 类似，服务器接受并开始处理请求，但请求未处理完成，未返回内容(响应体无数据)；</u>
    - 比如：在未更新网页的情况下，可确保浏览器继续显示当前文档；
  - <u>205 Reset Content：重置内容；表示服务器处理成功，此时用户终端应重置文档视图；</u>
    - 比如：可通过此返回码清除浏览器的表单域；
  - <u>206 Partial Content：表示部分内容，服务器成功处理了部分GET请求，使用 range  协议时返回部分响应内容时的响应码；</u>
    - 比如：使用场景为 HTTP 分块下载和断点续传，当然也会带上相应的响应头字段 Content-Range；
- 3XX：表示重定向状态，资源位置发生变动，需重新请求；
  - 300 Multiple Choices：多种选择，是一个特殊的重定向状态码，请求的资源可包括多个位置，会返回一个有多个链接选项的页面，由用户自行选择；
  - <u>301 Moved Permanently：永久重定向，请求的资源已被永久移动到新 URI，返回信息会包括新 URI，浏览器会自动定向到新 URI，且浏览器会作缓存优化，后续访问时自动访问缓存后的新 URI；</u>
  - <u>302 Found：临时重定向，与301类似，但资源只是临时被移动，客户端应继续使用原有URI，浏览器不作缓存优化；</u>
  - <u>303 See Other：临时重定向，类似于 302，请求的资源临时被移动到了别的URI上，但是明确表示客户端应该使用GET方法获取资源，即重向后的请求方法改为 `GET` 方法；</u>
  - <u>304 Not Modified：未修改，所请求的资源未修改，服务器返回此状态码时，表明服务端验证过期缓存有效后，要求客户端使用该缓存，不会返回任何资源；当协商缓存命中时返回的状态码；</u>
  - 305 Use Proxy：使用代理，所请求的资源必须通过代理访问；
  - 306 Unused：已经被废弃的HTTP状态码；
  - <u>307 Temporary Redirect：临时重定向，但是比 302 更明确，重定向的请求方法和实体都不允许变动；</u>
    - 比如：HSTS 协议，强制客户端使用 `https` 建立连接，若某网站从 `HTTP` 升级到 `HTTPS`，但还是以 http 形式访问时接收到；
  - 308：类似于 301，代表永久重定向，重定向后请求的方法和实体不允许变动；
  - **302 Found，基本的临时重定向**
  - **303 SeeOther，明确表示客户端应该使用GET方法**
  - **307 Temprary Redirect，请求方法和实体都不允许变动**

- 4XX：表示请求报文有误；
  - <u>400 Bad Request：服务器认为客户端出现了错误，但不明确，一般是 HTTP 请求格式错误；</u>
  - <u>401 Unauthorized：用户认证信息确实或者不正确；</u>
  - 402 Payment Required：保留码，将来使用；
  - <u>403 Forbidden：服务器理解请求客户端的请求，但拒绝执行此请求(原因有很多，比如法律禁止、信息敏感、数据保护等)；</u>
  - <u>404 Not Found：服务器没有找到对应的资源；</u>
  - 405 Method Not Allowed：客户端请求中的方法被禁止；
  - 406 Not Acceptable：服务器无法根据客户端请求的内容特性完成请求；
  - 407 Proxy Authentication Required：请求要求代理的身份认证，与 401 类似，对需要经由代理的请求，认证信息未通过代理服务器的验证；
  - 408 Request Timeout：服务器等待客户端发送的请求时间过长，超时；
  - 409 Conflict：服务器处理请求时发生了冲突；
    - 比如：服务器完成客户端的 PUT 请求；
  - 410 Gone：客户端请求的资源已不存在；
    - 注意：410 不同于 404：若资源过去存在，但现在被永久删除可使用 410 代码，亦可通过 301 码指定资源新位置；
  - 411 Length Required：服务器无法处理客户端发送的不带Content-Length的请求信息
  - 412 Precondition Failed：客户端请求信息的先决条件错误
  - 413 Request Entity Too Large：请求体过大，服务器无法处理，因此拒绝请求；
    - 注意：为防止客户端的连续请求，服务器可能会关闭连接。若只是服务器暂时无法处理，则会返回包含 Retry-After 的响应信息；
  - 414 Request-URI Too Long：请求行的 URI 过长，服务器无法处理；
  - 415 Unsupported Media Type：服务器无法处理请求附带的媒体格式；
  - 416 Requested range not satisfiable：客户端请求的范围无效；
  - 417 Expectation Failed：服务器无法满足 Expect 的请求头信息；
  - 429 Too Many Request：客户端发送请求过多；
  - 431 Request Header Fields Too Large：请求头的字段内容太大；

- 5XX：表示服务器端发生错误；
  - <u>500 Internal Server Error：服务器内部错误，且不属于以下错误类型，无法完成请求；</u>
  - <u>501 Not Implemented：表示服务器不支持请求的功能，无法完成请求</u>
  - 502 Bad Gateway：代理服务器无法获取到合法响应；
  - <u>503 Service Unavailable：表示服务器当前正忙(由于超载或系统维护)，服务器尚未准备好处理当前请求；</u>
  - 504 Gateway Time-out：充当网关或代理的服务器，未及时从远端服务器获取请求；
  - 505 HTTP Version not supported：服务器不支持请求的 HTTP 协议版本，无法完成处理；

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200907235842.png" style="zoom:50%;" align=""/>

<img src="https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200907235843.png" style="zoom:50%;" align=""/>



**<u>HTTP Acceptxx + Contentxx</u>**

数据类型：标记数据类型

- 客户端通过 Accept 字段表示想接收到的数据类型；
- 服务端通过 Content-type *表示发送数据的类型*；
  - text： text/html, text/plain, text/css 等；
  - image: image/gif, image/jpeg, image/png 等；
  - audio/video: audio/mpeg, video/mp4 等；
  - application: application/json, application/javascript, application/pdf, application/octet-stream；

压缩方式：标记对数据编码压缩的方式

- 客户端通过 Accept-Encoding 表示可接受的压缩方式；
- 服务端通过 Content-Encoding 表示对数据采取了何种压缩方式；
  - gzip: 当今最流行的压缩格式；
  - deflate：另外一种著名的压缩格式；
  - br：一种专门为 HTTP 发明的压缩算法；

支持语言：标记本机环境所支持的语言

- 客户端通过 Accept-Language 表示可支持的语言；
- 服务端通过 Content-Language 表示可支持的语言；

字符集：标记可接受的字符集

- 客户端通过 Accept-Charset 表示可支持的字符集；
- 服务端通过 Content-Type 表示可支持的字符集；



**<u>HTTP Cookie</u>**

![image-20200924101642914](https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924101643.png)

- 作用时间 & 作用域+时间：Max-Age & Expires +Domain & Path

![image-20200924101712053](https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924101712.png)

- 安全相关：Secure & HttpOnly & SameSite

![image-20200924101717748](https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924101717.png)



**<u>HTTP 缓存相关字段</u>**

<u>强缓存、协商缓存：见浏览器缓存</u>

<u>代理缓存—源服务器缓存控制</u>

- Cache-Control：源服务器通过在响应中加上 Cache-Control 字段来进行缓存控制，其值通常为：
  - public：允许代理服务器缓存；
  - private：禁止代理服务器缓存；此举能防范极私密数据，缓存到代理服务器，从而被恶意用户访问获取；
  - s-maxage & max-age：限定缓存在 <u>代理服务器</u> 可存放多长时间，`s` 即 `share`，与限制客户端缓存时间的 `max-age` 不冲突

- proxy-revalidate
  - must-revalidate：指示客户端缓存过期就去源服务器获取；
  - proxy-revalidate：指示代理服务器缓存过期后到源服务器获取；

<u>代理缓存—客户端缓存控制</u>

- max-stale & min-fresh：客户端的请求头中，可加入这 2 个字段，来对代理服务器上的缓存进行 <u>宽容</u> 和 <u>限制</u> 操作：
  - max-stale: 10：表示客户端从代理服务器拿缓存时，即使代理缓存过期也无事，只要过期时间在 10 秒内，即可从代理获取；
  - min-fresh: 5：表示代理缓存需要一定新鲜度，不要等到缓存刚好到期再拿，一定要在到期前 5 秒前的时间拿，否则拿不到
- only-if-cached：表明客户端只接受代理缓存，而不接受源服务器响应；若代理缓存无效，则直接返回 504（Gateway Timeout）



**<u>HTTP 代理记录相关字段</u>**

- 负载均衡：客户端请求只会先到达代理服务器，随后通过特定算法(随机算法、轮询、一致性hash、LRU)分发给不同源服务器，让各源服务器负载尽量均衡；
- 保障安全：利用心跳机制监控后台服务器，一旦发现故障机就移出服务器集群，并对其上下行数据进行过滤，对非法 IP 限流等；
- 缓存代理：将内容缓存到代理服务器，使客户端可直接从代理获取资源而不用去源服务器；

<u>代理记录字段</u>

Via：代理服务器需表明自身身份，在 HTTP 传输中留下痕迹，可通过字段 Via 实现记录，其值为在 HTTP 传输中报文传达的顺序：

X-Forwarded-For：记录 请求方(包括代理) IP 地址的字段，表示为谁转发

- 问题：其值会随着代理的变更而变更，即代理必须解析 HTTP 请求头，然后才可进行修改，比直接转发数据效率低；且在 HTTPS 通信加密的过程中，原始报文是不允许修改；

- 解决：通过 代理协议 解决：在HTTP 请求行上面加上以下格式文本：

- ```http
  // PROXY + TCP4/TCP6 + 请求方地址 + 接收方地址 + 请求端口 + 接收端口
  PROXY TCP4 0.0.0.1 0.0.0.2 1111 2222
  GET / HTTP/1.1
  ...
  ```

X-Real-IP：记录最初客户端的 IP 的字段，而不管经过多少代理；



**<u>HTTP 数据传输相关字段</u>**

<u>定长数据上传：Content-Length</u>

- 若设置值 < *实际报文长度会根据设置值截断*；
- *若设置值* > 实际报文长度则会报错："该网页无法正常运作"；

<u>不定长数据上传：Transfer-Encoding: chunked</u>

- 设置后 Content-Length 字段会被忽略；
- 基于长连接持续推送动态内容；

<u>大文件传输：Range</u>

对于大文件上传，为避免影响用户体验，HTTP 提供 <u>范围请求</u> 方式，允许客户端仅请求资源的某部分(前提是服务端支持 <u>范围请求</u>，可从服务端的响应报文获悉)，

```http
// 服务端告知客户端自身支持范围请求
Accept-Ranges: none
```

具体请求哪部分，客户端可通过 Range 请求字段确定，格式为 `bytes=x-y`，书写格式如下：

- **0-499**：表示从开始到第 499 个字节；
- **500**- ：表示从第 500 字节到文件终点；
- **-100**：表示文件的最后100个字节；

当服务器收到请求后，首先会验证范围 **是否合法**，若越界则返回 `416` 错误码，否则读取相应片段，返回 `206` 状态码；同时，服务器还会在响应报文头部添加  `Content-Range` 字段，此字段的格式根据请求头中 `Range` 字段的不同而不同；具体来说，请求 `单段数据` 和请求 `多段数据`，响应头是不一样的：

- 单段数据

- ```http
  // 单段数据
  Range: bytes=0-9
  // 响应报文:
  HTTP/1.1 206 Partial Content
  Content-Length: 10
  Accept-Ranges: bytes
  Content-Range: bytes 0-9/100
  
  // 上面是空行
  hello world
  // 其中 Content-Range 字段，0-9 表示请求的返回，100 表示资源的总大小；
  ```

- 多段数据

- ```http
  // 多段数据
  Range: bytes=0-9, 30-39
  // 响应报文:
  HTTP/1.1 206 Partial Content
  Content-Type: multipart/byteranges; boundary=00000010101 
  // 请求一定是多段数据请求, 响应体中的分隔符是 00000010101
  // 在响应体中各段数据之间会由这里指定的分隔符分开，而且在最后的分隔末尾添上 -- 表示结束；
  Content-Length: 189
  Connection: keep-alive
  Accept-Ranges: bytes
  
  
  --00000010101
  Content-Type: text/plain
  Content-Range: bytes 0-9/96
  
  i am xxxxx
  --00000010101
  Content-Type: text/plain
  Content-Range: bytes 20-29/96
  
  eex jspy e
  --00000010101--
  
  ```

<u>表单数据提交</u>

Content-Type: application/x-www-form-urlencoded

- 数据会被编码成以 & 分隔的键值对；然后字母原样，但字符以 URL编码方式 编码；
- 比如：{a: 1, b: 2} -> a=1&b=2 -> "a%3D1%26b%3D2"

Content-Type: multipart/form-data

- 每个表单元素均为独立的资源表述；数据会被拆分成多个部分、之间通过分隔符分隔、每部分的表述均有 HTTP 头部描述子包体，比如 Content-Type，在最后的分隔符会加上--表示结束；

- 实际中，图片等文件上传，基本采用 multipart/form-data 而非 application/x-www-form-urlencoded；因没必要做 URL 编码；

- 注意：请求头中的 Content-Type 字段会包含 boundary(分隔符)，此值值由浏览器默认指定；

- 比如： Content-Type: multipart/form-data;boundary=----WebkitFormBoundaryRRJKeWfHPGrS4LKe；

- ```http
  Content-Disposition: form-data;name="data1";
  Content-Type: text/plain
  data1
  ----WebkitFormBoundaryRRJKeWfHPGrS4LKe
  Content-Disposition: form-data;name="data2";
  Content-Type: text/plain
  data2
  ----WebkitFormBoundaryRRJKeWfHPGrS4LKe--
  ```



### 5-3、HTTPS

**<u>HTTPS 基本背景</u>**

![image-20200924104304484](https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924104304.png)



**<u>HTTPS 加密演变</u>**

<u>对称加密</u>：同一个密钥加解密；意义：在一定程度上保证数据的安全性，但密钥一旦泄露(密钥在传输过程中被截获)，传输内容就会暴露，因此需要寻找一种更为安全传递密钥的方法

- 算法：AES、CHACHA20
- 分组模式：CBC、ECB、CTR、GCM、POLY1306

<u>非对称加密</u>：公钥加密私钥解密，相反亦可；意义：虽解决由于密钥被获取而导致传输内容泄露问题，但中间人仍可用 篡改(劫持)公钥的方式来获取/篡改传输内容，且非对称加密的性能比对称加密的差；

- 算法：RSA、ECDHE

<u>数字证书</u>：前面问题在于：客户端不知道公钥是由服务端返回，还是中间人返回；由此可引入一个第三方认证的环节：即第三方使用私钥加密客户端的 自己的公钥，浏览器已内置一些权威第三方认证机构的公钥，浏览器会使用第三方的公钥来解开在服务端用第三方的私钥加密过的，发往客户端的公钥，从而使得客户端获取公钥(它的思想是中间人无法获取此公钥，资质审核)，若能成功解密，则说明获取到公钥是合法的(但仍无法确定是否被篡改，因为"水平厉害"的中间人也能申请证书，只能防范"水平一般"的中间人)；意义：第三方认证也未能完全解决问题，第三方认证是面向所有人，中间人也能申请证书，若中间人使用自己证书掉包原证书，客户端还是无法确认公钥真伪；

- 颁发流程：提交申请、验证通过、对上交信息数字签名得到摘要A，并CA私钥加密，返回上交信息与摘要A组成的证书；

- 验证流程：利用CA公钥解密证书，得到摘要A，利用 Hash 函数对上交信息进行同样的签名过程，得到摘要B，比对两者以验证；

![image-20200924104554197](https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924104554.png)

<u>数字签名</u>：上述问题在于：传输过程中内容可能被篡改，证书可能被调包，为解决通信方身份遭伪装问题，验明通信方的身份；此时可引入 数字签名，以保证数据完整性(一旦中途被篡改即可发现)

![image-20200924104653401](https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924104653.png)



**<u>HTTPS 加密应用</u>**

- 对称加密应用
  - 交换随机值AB，然后用协商后的加密方法加密得到共同密钥
- 非对称加密应用
  - 与上述不同的是：服务端在交换自己随机值B时，还回传了公钥，此后客户端公钥加解密服务端私钥加解密内容
- 上述两种方式结合应用
  - 与上述不同的是：客户端利用服务端回传的公钥加密，随机值C(即非利用公钥传送通讯信息)回送服务端，再利用随机值ABC+协商的加密方法生成对称密钥
- 再加上数字证书的使用
  - 与上述不同的是：服务端在交换自己随机值B时，回传的不是简单公钥，而是利用数字签名的数字证书(含公钥)，客户端验证数字证书，验证通过则发生上述流程
  - 首先，读取证书中的明文内容；CA 进行数字证书的签名时会保存一个 Hash 函数，此函数用来计算明文内容得到 信息A；
  - 然后，用公钥解密明文内容得到 信息B，将两份信息进行比对，一致则表示认证合法；
  - 注意：CA 的可信任性通过层级保证，若浏览器无法信任 CA，其会查找 CA 的上级 CA，以同样的信息比对方式验证上级 CA 的合法性，而一般根级的 CA 会内置在操作系统当中；若向上找没有找到根级的 CA，则将被视为不合法；



**<u>HTTPS TLS 握手过程</u>**

<u>TLS 1.1：传统 RSA 握手</u>

- 首先，浏览器向服务器发送 A、TSL 版本号、加密方法套件(含 RSA)；
- 然后，服务器接收后，给浏览器返 B、确认 TSL 版本号、加密方法套件(含 RSA)、数字证书(含公钥)；
  - 此时，两者拥有三样相同凭证：A、B、加密方法；而服务器含公私两钥，客户端含公钥；
- 然后，在浏览器接收之后，就会开始验证数字证书；若验证通过，浏览器利用 RSA 生成另一个随机数 C，并利用服务器公钥(从证书中获取)进行加密，回传给服务器，后者则用私钥解密得到 C；
  - 此时，两者拥有四样相同凭证：A、B、C、加密方法；而服务器含公私两钥，客户端含公钥；
  - 注意：证书其实包含了三个东西：公钥、数字签名后的明文内容、明文内容
- 然后，双方通过相同加密方法，利用三个随机数，通过一个 伪随机函数 生成最终 密钥；
- 最后，浏览器和服务器使用同样的密钥进行通信，即使用 对称加密；
- 问题：每次利用 RSA 生成 C，不具备向前安全性

![image-20200924104833999](https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924104834.png)



<u>TLS 1.2 握手：采用 ECDHE</u> 非对称加密算法

- 与 RSA 明显不同的是：使用了安全性更高的 ECDHE 算法：服务器回传客户端随机数B、证书时还回传了随机数Bplus；且前者通过证书验证后直接利用 RSA 生成随机数C，而后者验证通过后先是生成随机数Aplus并回传服务端，然后根据随机数 Aplus+Bplus，结合 ECDHE 生成随机数 Cplus (确保了向前安全性，因为前者随机数 C 值一旦生成即固定不变化存在一定危险)；然后客户端将 随机数AB+Cplus 通过加密算法，加密生成对称密钥
- 即比 RSA 流程多出了 Aplus、Bplus、Cplus 的生成过程，前两者用于生成 Cplus，分别通过验证响应未被篡改后生成、服务器响应得到，完美确保安全性
- 之前 RSA 是直接生成 C，而此处是接收 B+，生成A+，回传A+，双方利用 ECDHE 生成 C+，然后再利用A+B+C+生成对称密钥

![image-20200924104942490](https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924104942.png)

![image-20200924105009544](https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924105009.png)

- TLS False Start 提前发送 HTTP

- 注意事项

![image-20200924105424075](https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924105424.png)

<u>TLS 1.3 握手：改进</u>：TLS 1.3 主要对 TLS 1.2 做了系列改进：废除大量算法，提升安全性，同时利用会话复用，节省重新生成密钥时间，并利用 PSK 实现 0-RTT 连接：

- 废除有安全漏洞的加密算法
  - 对称加密算法：保留 AES 和 CHACHA20；
  - 分组模式：保留 GCM 和 POLY1305；
  - 哈希摘要算法：保留 SHA256 和 SHA384；
- 1-RTT握手：TLS 1.3 握手流程大体与 TLS1.2 类似，但比后者减少一个 RTT， 服务端不必等待对方验证数字证书后才能拿到 client_params，而是直接在首次握手时即可拿到
  - 会话复用—1RTT优化
    - Session ID 方式：首先，客户端和服务器首次连接后各自保存会话 ID，并存储会话密钥；然后，当再次连接时，客户端发送会话 ID，服务器根据 ID 是否存在，选择直接复用先前会话状态、重用会话密钥；或拒绝；缺点是当客户端数量庞大时，对服务端存储、性能要求非常大；
    - Session Ticket 方式：针对上一种方式存在的问题，将服务端压力分摊给客户端(卑鄙)；首先，双方连接成功后，服务器 加密并将 Session Ticket 发给客户端并告知存储；然后客户端下次重连时，发送 Ticket，服务端解密后验证过期与否，若无则直接恢复先前会话状态；缺点是存在安全问题，每次用一个固定密钥来解密 Ticket 数据，一旦黑客拿到密钥，先前所有历史记录也被破解，故密钥需要定期进行更换；
  - PSK(Pre-Shared Key)—0RTT优化：
  - 优化至 0RTT：在发送 Session Ticket 的同时携带应用数据，而不用等到服务端确认；缺点是存在安全问题，中间人截获 PSK 数据，不断向服务器发送，类似于 TCP 首次握手即携带数据，增加了服务器被攻击的风险





### 5-4、HTTP2/3

**<u>HTTP2</u>**：

HTTPS 专注于安全提升，而 HTTP/2 则专注性能方面的提升(头部压缩、多路复用)，并增加诸多功能(设置请求优先级、服务器推送)；

<u>二进制帧结构</u>：在之前 HTTP 版本中，是通过文本的方式传输数据；但在 HTTP/2 中引入了新的编码机制，所有传输的数据都会被分割，并采用二进制格式编码；HTTP/2 将报文全部换成二进制格式，即全部传输01串，以方便机器解析，减少因字符多义性的状态问题的判断，提升解析效率；原来的 *Headers* + Body 的报文格式被分拆成二进制帧，并使用 Headers帧 存放头部字段，用 Data帧 存放请求体数据；每个二进制帧由 帧头—Frame Header 和 帧体—Frame Payload 组成；

![image-20200924105636517](https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924105636.png)

- 帧长度：表示 帧体 的长度；
- 帧类型：可分为 数据帧 和 控制帧 2 种；前者用来存放 HTTP 报文，后者用来管理 流 的传输，比如实现 优先级 与 流量控制；
- 帧标志：共有 8 个标志位，常用的有 END_HEADERS 表示头数据结束，END_STREAM 表示单方向数据发送结束；
- 流标识符—Stream ID：供接收方从乱序二进制帧中选择出 ID 相同的帧，并按顺序(ID按顺序递增)还原成请求/响应报文；
- 注意：所谓乱序，指的是不同 ID 的 Stream 乱序发送，但同一 Stream ID 的帧一定是按顺序传输。二进制帧到达后对方会将 Stream ID 相同的二进制帧顺序组装(通过 TCP 顺序性实现)成完整的报文；



<u>流概念与状态变化</u>：通信双方均可给对方发送二进制帧，这种二进制帧的双向传输的序列，称作 流(Stream)；而在 HTTP/2 请求和响应过程中，流的状态变化是通过标志位实现：

- 首先，双方均未空闲状态，当客户端发送 Headers帧 后，开始分配 Stream ID ，此时客户端的 流(序列) 打开，而服务端在接收后也打开 流(序列) ，双方均打开 流(序列) 后，即可互相传递二进制帧；
- 然后，当客户端需要关闭时，向服务端发送 END_STREAM帧，进入 半关闭状态，此时客户端只能接收数据，不能发送数据；
- 然后，当服务端收到 END_STREAM帧，也进入 半关闭状态，此时服务端只能发送数据，不能接收数据，与客户端情况相反；
- 随后，服务端向客户端发送 END_STREAM帧，表示数据发送完毕，双方进入 关闭状态；
- 注意：若下次开启新的 流(序列) ，流 ID 需自增直到上限为止(4字节，最高位保留，范围 0-2^31 ≈ 21 亿)，到达上限后开一个新的 TCP 连接重头开始计数；

<u>流的传输特性</u>

- 并发性：一个 HTTP/2 连接可同时发送多个帧，与 HTTP/1 不同，这是实现多路复用的基础；
- 自增性：流 ID 不可重用，按顺序递增，达到上限之后又新开 TCP 连接从头开始(没有回绕问题)；
- 双向性：客户端和服务端均可创建流，互不干扰，双方均可作为发送方或接收方；
- 可设置优先级：通过设置数据帧的优先级，让服务端先处理重要资源，优化用户体验；

<u>HTTP2 性能提升—头部压缩</u>

- HTTP/1.1 及低版本中，使用文本的形式传输报文，在携带 cookie 的情况下，可能每次都需要重复传输几百到几千的字节；虽然 请求报文请求体 可通过 Content-Encoding 头部字段，指定压缩算法压缩请求体；HTTP/2 后，请求报文头部 也可通过 HPACK 压缩算法压缩 (GET 请求头部往往是主体，优化力度大)，
- HPACK 算法
  - 首先，服务器和客户端分别建立、维护哈希表，并将用到的字段存放在此表中，随后在传输时对于先前出现过的值，只需将把索引值传给对方即可，对方拿到索引后查表即可完成字段搜索；让请求头字段得到极大程度的精简和复用；
  - 然后，对于整数和字符串进行 哈夫曼编码，此编码原理是：先将所有出现的字符建立一张索引表，然后让出现次数多的字符对应的索引尽可能短，传输时也是传输这样的索引序列，可达到非常高的压缩率；

<u>HTTP2 性能提升—多路复用</u>

- 在 HTTP/2 中，有两个非常重要的概念，分别是帧 (frame) 和流 (stream)；帧代表着最小的数据单位，每个帧会标识出该帧属于哪个流；流也就是多个帧组成的数据流；多路复用：是 HTTP/2 在一个域名里，只使用一个TCP⻓连接来传输数据，而且请求直接是并行的、非阻塞的，也就是说在一个 TCP 连接中可以存在多条流；可发送多个请求，对端可以通过帧中的标识知道属于哪个请求；通过这个技术，可避免 HTTP 旧版本中的队头阻塞问题、减少多条 TCP 连接竞争带宽问题，极大的提高传输性能；
- 实现原理： HTTP/2 引入一个二进制分帧层，客户端和服务端进行传输时，数据会先经过二进制分帧层处理，转化为一个个带有请求 ID 的帧，这些帧在传输完成后再根据 ID 组合成对应的数据；通俗说就是：多路复用即 HTTP/2 用 流 来在一个 TCP 连接上来进行多个数据帧的通信；因通过拆分报文为二进制帧，而一个 HTTP/2 连接可同时发送多个帧，且接收端可通过相同 StreamID 帧顺序组合还原报文，发送无先后关系，不用排队发送，故 HTTP/2 从协议层面解决 HTTP队头阻塞问题(前一请求未处理完，后续请求被阻塞(不同于 TCP 队头阻塞，后者是前一个报文数据包未收到就不会将提前到达的后续数据包向上传递，为数据包层面，HTTP 队头阻塞是请求层面))

<u>HTTP2功能增加</u>

- 设置请求优先级
- 服务器推送



**<u>HTTP3</u>**

![截屏2020-09-24 上午11.01.14](https://leibnize-picbed.oss-cn-shenzhen.aliyuncs.com/img/20200924110119.png)







## 六、WebSocket

特例：看 websocket MD 即可；

